{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://github.com/cvdfoundation/fashionpedia 여기서 Training images, Validation and test images, instances_attributes_train2020, instances_attributes_val2020 다운로드\n",
    "2. 현재 주피터 노트북 위치 기준으로 ./fashionpedia 디렉터리 생성\n",
    "   - images 폴더 아래에 이미지 train, test 폴더 위치시킨다.\n",
    "   - instances_attributes_train2020.json, instances_attributes_val2020.json 위치시킨다. 파일명에서 val -> test로 변경.\n",
    "3. 이후 아래 코드 실행하면 huggingface dataset 포맷으로 데이터셋이 생성됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset, Value, Sequence, ClassLabel, Features, DatasetDict, concatenate_datasets, load_from_disk\n",
    "from datasets import Image as DImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotation_dict(attribute_dict):\n",
    "    annotation_dict = defaultdict(list)\n",
    "    for annotation in attribute_dict['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        category_id = annotation['category_id']\n",
    "        bbox = annotation['bbox']\n",
    "        area = annotation['area']\n",
    "        iscrowd = annotation['iscrowd']\n",
    "\n",
    "        annotation_dict[image_id].append(\n",
    "            {\n",
    "                'category_id': category_id,\n",
    "                'bbox': bbox,\n",
    "                'area': area,\n",
    "                'iscrowd': iscrowd,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return annotation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_dict(attribute_dict):\n",
    "    image_dict = {}\n",
    "    for image in attribute_dict['images']:\n",
    "        image_id = image['id']\n",
    "        width = image['width']\n",
    "        height = image['height']\n",
    "        image_fname = image['file_name']\n",
    "\n",
    "        image_dict[image_id] = {\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'image_fname': image_fname,\n",
    "        }\n",
    "\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_norm_dict = {\n",
    "    'skirt': 'bottom',\n",
    "    'top, t-shirt, sweatshirt': 'top',\n",
    "    'sweater': 'top',\n",
    "    'cape': 'outer',\n",
    "    'pants': 'bottom',\n",
    "    'shoe': 'shoes',\n",
    "    'coat': 'outer',\n",
    "    'shirt, blouse': 'top',\n",
    "    'dress': 'dress',\n",
    "    'jumpsuit': 'jumpsuit',\n",
    "    'cardigan': 'outer',\n",
    "    'bag, wallet': 'bag',\n",
    "    'hat': 'hat',\n",
    "    'jacket': 'outer',\n",
    "    'tights, stockings': 'bottom',\n",
    "    'vest': 'outer',\n",
    "    'shorts': 'bottom',\n",
    "    'glove': 'glove',\n",
    "    'watch': 'watch',\n",
    "    'belt': 'belt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['bag', 'bottom', 'dress', 'hat', 'outer', 'shoes', 'top']\n",
    "labels = ['bag', 'belt', 'bottom', 'dress', 'eyewear', 'glove', 'hat', 'jumpsuit', 'outer', 'shoes', 'top', 'watch']\n",
    "\n",
    "id2label = {\n",
    "    i: c for (i, c) in enumerate(labels)\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "    c: i for (i, c) in enumerate(labels)\n",
    "}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_split(split):\n",
    "\n",
    "    with open(f'./fashionpedia/instances_attributes_{split}2020.json', 'r') as f:\n",
    "        attribute_dict = json.load(f)\n",
    "\n",
    "    annotation_dict = create_annotation_dict(attribute_dict)\n",
    "    image_dict = create_image_dict(attribute_dict)\n",
    "    category_id_to_name = {}\n",
    "    for obj in attribute_dict['categories']:\n",
    "        category_id_to_name[obj['id']] = obj['name']\n",
    "\n",
    "\n",
    "    bbox_id = 0\n",
    "\n",
    "    data_list = []\n",
    "    for image_id, image_obj in tqdm(image_dict.items()):\n",
    "        width = image_obj['width']\n",
    "        height = image_obj['height']\n",
    "        image_fname = image_obj['image_fname']\n",
    "        image = Image.open(f\"./fashionpedia/images/{split}/{image_fname}\").convert('RGB')\n",
    "        jpeg_buffer = io.BytesIO()\n",
    "        image.save(jpeg_buffer, format='JPEG')\n",
    "        jpeg_buffer.seek(0)\n",
    "        image = Image.open(jpeg_buffer)\n",
    "\n",
    "        data = {}\n",
    "        data = {\n",
    "            'image_id': image_id,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'image': image,\n",
    "        }\n",
    "\n",
    "        objects = []\n",
    "        is_valid = True\n",
    "        for obj in annotation_dict[image_id]:\n",
    "            category_id = obj['category_id']\n",
    "            norm_category = category_norm_dict.get(category_id_to_name[category_id])\n",
    "            if not norm_category:\n",
    "                continue\n",
    "\n",
    "            norm_category_id = label2id[norm_category]\n",
    "            bbox = obj['bbox']\n",
    "\n",
    "            x1, y1, width, height = bbox\n",
    "            if not (x1 >= 0 and y1 >= 0 and width > 0 and height > 0):\n",
    "                is_valid = False\n",
    "                break\n",
    "            \n",
    "            area = obj['area']\n",
    "            iscrowd = obj['iscrowd']\n",
    "\n",
    "            objects.append(\n",
    "                {\n",
    "                    'category': norm_category_id,\n",
    "                    'bbox_id': bbox_id,\n",
    "                    'bbox': bbox,\n",
    "                    'area': area,\n",
    "                    'iscrowd': iscrowd,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            bbox_id += 1\n",
    "\n",
    "        if not is_valid:\n",
    "            continue\n",
    "        \n",
    "        if objects:\n",
    "            data['objects'] = objects\n",
    "            data_list.append(data)\n",
    "\n",
    "    class_label = ClassLabel(names=labels)\n",
    "    features = Features({\n",
    "        'image_id': Value('int64'),\n",
    "        'width': Value('int64'),\n",
    "        'height': Value('int64'),\n",
    "        'image': DImage(decode=True),\n",
    "        'objects': Sequence({\n",
    "            'bbox_id': Value('int64'),\n",
    "            'category': class_label,\n",
    "            'bbox': Sequence(Value('float64'), length=4),\n",
    "            'area': Value('int64')\n",
    "        })\n",
    "    })\n",
    "    \n",
    "    # 메모리 부족으로 나눠서 처리\n",
    "    sub_datasets = []\n",
    "    for i in tqdm(range(0, len(data_list), 500)):\n",
    "        sub_data = data_list[i: i + 500]\n",
    "        sub_dataset = Dataset.from_list(sub_data, features=features)\n",
    "        sub_datasets.append(sub_dataset)\n",
    "\n",
    "    dataset = concatenate_datasets(sub_datasets)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = create_dataset_split('train')\n",
    "split_test = create_dataset_split('test')\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': split_train,\n",
    "    'test': split_test, \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(f'./fashionpedia_hf_dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion-visual-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
