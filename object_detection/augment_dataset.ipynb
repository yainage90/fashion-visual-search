{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, Dataset, Value, Sequence, Features, concatenate_datasets\n",
    "from datasets import Image as DImage\n",
    "import huggingface_hub\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('./object_detection_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset['train'].features['objects'].feature['category'].names\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_bounds(bbox):\n",
    "    \"\"\"Get the minimum and maximum coordinates of all objects\"\"\"\n",
    "    x_min = min(box[0] for box in bbox)\n",
    "    y_min = min(box[1] for box in bbox)\n",
    "    x_max = max(box[0] + box[2] for box in bbox)\n",
    "    y_max = max(box[1] + box[3] for box in bbox)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def is_bbox_inside(bbox, crop_bounds):\n",
    "    \"\"\"Check if bbox is inside crop bounds\"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    x2, y2 = x + w, y + h\n",
    "    crop_x1, crop_y1, crop_x2, crop_y2 = crop_bounds\n",
    "    return (x >= crop_x1 and x2 <= crop_x2 and \n",
    "            y >= crop_y1 and y2 <= crop_y2)\n",
    "\n",
    "def is_bbox_partially_inside(bbox, crop_bounds):\n",
    "    \"\"\"Check if bbox is partially inside crop bounds\"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    x2, y2 = x + w, y + h\n",
    "    crop_x1, crop_y1, crop_x2, crop_y2 = crop_bounds\n",
    "    return not (x2 < crop_x1 or x > crop_x2 or \n",
    "               y2 < crop_y1 or y > crop_y2)\n",
    "\n",
    "def adjust_bbox_coordinates(bbox, crop_bounds):\n",
    "    \"\"\"Adjust bbox coordinates relative to crop bounds\"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    crop_x1, crop_y1, _, _ = crop_bounds\n",
    "    return [int(x - crop_x1), int(y - crop_y1), int(w), int(h)]\n",
    "\n",
    "def augment_image(example, image_id):\n",
    "    \"\"\"\n",
    "    Augment a single image by randomly selecting and cropping around an object\n",
    "    \"\"\"\n",
    "    # Convert image bytes to PIL Image\n",
    "    image = example['image']\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Randomly select an object\n",
    "    idx = random.randint(0, len(example['objects']['bbox']) - 1)\n",
    "    selected_bbox = example['objects']['bbox'][idx]\n",
    "    \n",
    "    # Calculate crop bounds with margin\n",
    "    margin = random.uniform(0.3, 0.9)\n",
    "    x, y, w, h = selected_bbox\n",
    "    margin_w = int(w * margin)\n",
    "    margin_h = int(h * margin)\n",
    "    \n",
    "    crop_x1 = max(0, x - margin_w)\n",
    "    crop_y1 = max(0, y - margin_h)\n",
    "    crop_x2 = min(width, x + w + margin_w)\n",
    "    crop_y2 = min(height, y + h + margin_h)\n",
    "    \n",
    "    # Crop image\n",
    "    cropped_img = image.crop((crop_x1, crop_y1, crop_x2, crop_y2))\n",
    "    jpeg_buffer = io.BytesIO()\n",
    "    cropped_img.save(jpeg_buffer, format='JPEG')\n",
    "    jpeg_buffer.seek(0)\n",
    "    cropped_img = Image.open(jpeg_buffer)\n",
    "\n",
    "    \n",
    "    # Create new annotation\n",
    "    new_annotation = {\n",
    "        'bbox_id': [],\n",
    "        'category': [],\n",
    "        'bbox': [],\n",
    "        'area': []\n",
    "    }\n",
    "    \n",
    "    crop_bounds = (crop_x1, crop_y1, crop_x2, crop_y2)\n",
    "    \n",
    "    # Check each bbox and include if it's inside the crop\n",
    "    for i in range(len(example['objects']['bbox'])):\n",
    "        if is_bbox_partially_inside(example['objects']['bbox'][i], crop_bounds):\n",
    "            new_bbox = adjust_bbox_coordinates(example['objects']['bbox'][i], crop_bounds)\n",
    "            if new_bbox[0] < 0:\n",
    "                if new_bbox[2] + new_bbox[0] > 0.5 * example['objects']['bbox'][i][2]:\n",
    "                    new_bbox[2] = new_bbox[2] + new_bbox[0]\n",
    "                    new_bbox[0] = 0\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if new_bbox[1] < 0:\n",
    "                if new_bbox[3] + new_bbox[1] > 0.4 * example['objects']['bbox'][i][3]:\n",
    "                    new_bbox[3] = new_bbox[3] + new_bbox[1]\n",
    "                    new_bbox[1] = 0\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if (new_x2 := new_bbox[0] + new_bbox[2]) > cropped_img.width:\n",
    "                if new_bbox[2] - (new_x2 - cropped_img.width) > 0.5 * example['objects']['bbox'][i][2]:\n",
    "                    new_bbox[2] = new_bbox[2] - (new_x2 - cropped_img.width)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if (new_y2 := new_bbox[1] + new_bbox[3]) > cropped_img.height:\n",
    "                if new_bbox[3] - (new_y2 - cropped_img.height) > 0.4 * example['objects']['bbox'][i][3]:\n",
    "                    new_bbox[3] = new_bbox[3] - (new_y2 - cropped_img.height)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            new_annotation['bbox_id'].append(example['objects']['bbox_id'][i])\n",
    "            new_annotation['category'].append(example['objects']['category'][i])\n",
    "            new_annotation['bbox'].append(new_bbox)\n",
    "            new_annotation['area'].append(example['objects']['area'][i])\n",
    "    \n",
    "    return {\n",
    "        'image_id': image_id,\n",
    "        'width': cropped_img.width,\n",
    "        'height': cropped_img.height,\n",
    "        'image': cropped_img,\n",
    "        'objects': new_annotation,\n",
    "    }\n",
    "\n",
    "def augment_dataset(dataset, num_augmentations=1):\n",
    "    \"\"\"\n",
    "    Augment the entire dataset\n",
    "    \"\"\"\n",
    "    augmented_examples = []\n",
    "    \n",
    "    image_id = max(dataset['image_id']) + 1\n",
    "\n",
    "    for example in tqdm(dataset):\n",
    "        for _ in range(num_augmentations):\n",
    "            if len(example['objects']['bbox_id']) == 1:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                aug_example = augment_image(example, image_id)\n",
    "                if len(example['objects']['bbox_id']) == len(aug_example['objects']['bbox_id']):\n",
    "                    continue\n",
    "                augmented_examples.append(aug_example)\n",
    "                image_id += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error augmenting image: {e}\")\n",
    "                continue\n",
    "    \n",
    "\n",
    "    class_label = dataset.features['objects'].feature['category']\n",
    "    features = Features({\n",
    "        'image_id': Value('int64'),\n",
    "        'width': Value('int64'),\n",
    "        'height': Value('int64'),\n",
    "        'image': DImage(decode=True),\n",
    "        'objects': Sequence({\n",
    "            'bbox_id': Value('int64'),\n",
    "            'category': class_label,\n",
    "            'bbox': Sequence(Value('float64'), length=4),\n",
    "            'area': Value('int64')\n",
    "        })\n",
    "    })\n",
    "    \n",
    "    # 메모리 부족으로 나눠서 처리\n",
    "    sub_datasets = []\n",
    "    for i in tqdm(range(0, len(augmented_examples), 500)):\n",
    "        sub_data = augmented_examples[i: i + 500]\n",
    "        sub_dataset = Dataset.from_list(sub_data, features=features)\n",
    "        sub_datasets.append(sub_dataset)\n",
    "\n",
    "    dataset = concatenate_datasets(sub_datasets)\n",
    "    dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "augmented_dataset = augment_dataset(concatenate_datasets([dataset['train'], dataset['test']]), num_augmentations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(augmented_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = concatenate_datasets([dataset['train'], dataset['test'], augmented_dataset['train'], augmented_dataset['test']])\n",
    "merged_dataset = merged_dataset.train_test_split(test_size=0.05)\n",
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample():\n",
    "    idx = random.randint(1, 50000)\n",
    "    print(idx)\n",
    "    sample = dataset['train'][idx]\n",
    "    image = sample['image']\n",
    "    bboxes = sample['objects']['bbox']\n",
    "    categories = sample['objects']['category']\n",
    "\n",
    "    draw_image = image.copy()\n",
    "    draw = ImageDraw.Draw(draw_image)\n",
    "\n",
    "    for category, bbox in zip(categories, bboxes):\n",
    "        draw.rectangle((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]), outline=\"green\", width=3)\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(draw_image)\n",
    "    plt.show()\n",
    "\n",
    "    print(f'sample: {len(sample['objects']['bbox_id'])}')\n",
    "    return sample\n",
    "\n",
    "\n",
    "def show_augment(sample):\n",
    "    aug = augment_image(sample, image_id=1)\n",
    "    image = aug['image']\n",
    "    bboxes = aug['objects']['bbox']\n",
    "    categories = aug['objects']['category']\n",
    "\n",
    "    draw_image = image.copy()\n",
    "    draw = ImageDraw.Draw(draw_image)\n",
    "\n",
    "    for category, bbox in zip(categories, bboxes):\n",
    "        draw.rectangle((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]), outline=\"green\", width=3)\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(draw_image)\n",
    "    plt.show()\n",
    "\n",
    "    print(f'augment: {len(aug['objects']['bbox_id'])}')\n",
    "    print(aug['objects'])\n",
    "    \n",
    "sample = show_sample()\n",
    "show_augment(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion-visual-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
